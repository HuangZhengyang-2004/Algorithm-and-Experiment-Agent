# 场景设计分析报告

## 核心发现

**所有场景使用完全相同的 `experiment.py` 代码**
- MD5: `05bd2c1d9ff8ad04ecef361d2b8f5eb7`
- 代码文件：380 行
- 差异实现方式：**仅通过命令行参数**

---

## 5个场景的详细对比

### 场景 1: IID Baseline Convergence
**目标**: 评估 SFedAvg vs FedAvg 在 IID 数据下的收敛速度和稳定性

**关键参数**:
```bash
--algo=sfedavg
--rounds=50         # 较少轮次
--clients=10        # 10个客户端
--client_frac=0.5   # 50% 客户端参与
--local_steps=5     # 较少本地步数
--lr=0.1            # 较高学习率
--momentum=0.9
--batch_size=64
--subspace_dim=16   # 较小子空间维度
--seed=42
--samples=6000      # 中等数据量
--features=20       # 中等特征数
--classes=3         # 3类问题
--train_ratio=0.8
```

**数据特点**: 
- IID 分区（均匀分布）
- 无标签噪声
- 中等规模

---

### 场景 2: Non-IID Client Drift Stress Test
**目标**: 评估 Non-IID 数据分布下的客户端漂移鲁棒性

**关键参数差异**:
```bash
--rounds=60         # ⬆️ 增加10轮（因为Non-IID更难收敛）
--local_steps=10    # ⬆️ 本地步数翻倍（增强客户端漂移）
--seed=123          # 🔄 不同随机种子
```

**其他参数相同**: clients=10, client_frac=0.5, lr=0.1, samples=6000, features=20, classes=3

**数据特点**: 
- **Non-IID 分区**（每个客户端主要持有1-2个类的样本）
- 更长的本地训练加剧客户端漂移

---

### 场景 3: Label Noise Robustness
**目标**: 评估对标签噪声的鲁棒性

**关键参数差异**:
```bash
--rounds=50         # 与场景1相同
--local_steps=5     # 与场景1相同
--seed=7            # 🔄 不同随机种子
```

**其他参数相同**: 与场景1基本一致

**数据特点**: 
- IID 分区
- **20% 标签翻转**（随机引入噪声标签）
- 测试算法对噪声的鲁棒性

---

### 场景 4: Scalability with Large Model and Dataset
**目标**: 测试大规模数据和模型下的可扩展性

**关键参数差异**:
```bash
--rounds=100        # ⬆️⬆️ 轮次翻倍
--clients=50        # ⬆️⬆️⬆️ 客户端数量 x5
--client_frac=0.2   # ⬇️ 参与率降低（但绝对数量仍是10个）
--lr=0.05           # ⬇️ 学习率减半（大规模设置需要更保守）
--batch_size=128    # ⬆️⬆️ 批量大小翻倍
--subspace_dim=128  # ⬆️⬆️⬆️ 子空间维度 x8
--seed=23           # 🔄 不同随机种子
--samples=60000     # ⬆️⬆️⬆️ 数据量 x10
--features=100      # ⬆️⬆️⬆️ 特征数 x5
--classes=10        # ⬆️⬆️ 类别数 x3
```

**数据特点**: 
- **大规模设置**（60k样本，100维特征，10类）
- 更多客户端（50个）
- 测试通信效率和计算可扩展性

---

### 场景 5: Edge Case - Sparse Participation & Long Local Training
**目标**: 探测极端情况下的失败模式

**关键参数差异**:
```bash
--rounds=80         # ⬆️ 增加30轮（因为稀疏参与需要更多轮次）
--clients=20        # ⬆️⬆️ 客户端数量翻倍
--client_frac=0.1   # ⬇️⬇️⬇️⬇️ 极低参与率（仅2个客户端）
--local_steps=20    # ⬆️⬆️⬆️⬆️ 极长本地训练（最强漂移）
--lr=0.05           # ⬇️ 学习率减半（稳定性考虑）
--subspace_dim=8    # ⬇️⬇️ 极小子空间（测试极限）
--seed=17           # 🔄 不同随机种子
--samples=12000     # ⬆️⬆️ 数据量翻倍
--features=30       # ⬆️ 特征数增加50%
--classes=4         # ⬆️ 类别数增加
```

**数据特点**: 
- **Non-IID + 类别不平衡**
- **极低参与率**（10%）
- **极长本地训练**（20步）
- 故意制造极端漂移场景

---

## 参数对比表

| 参数 | 场景1 (IID) | 场景2 (Non-IID) | 场景3 (Noise) | 场景4 (Scale) | 场景5 (Edge) |
|------|-------------|----------------|---------------|---------------|--------------|
| **rounds** | 50 | 60 | 50 | **100** | 80 |
| **clients** | 10 | 10 | 10 | **50** | **20** |
| **client_frac** | 0.5 | 0.5 | 0.5 | 0.2 | **0.1** |
| **local_steps** | 5 | **10** | 5 | 5 | **20** |
| **lr** | 0.1 | 0.1 | 0.1 | **0.05** | **0.05** |
| **batch_size** | 64 | 64 | 64 | **128** | 64 |
| **subspace_dim** | 16 | 16 | 16 | **128** | **8** |
| **samples** | 6000 | 6000 | 6000 | **60000** | **12000** |
| **features** | 20 | 20 | 20 | **100** | **30** |
| **classes** | 3 | 3 | 3 | **10** | **4** |
| **seed** | 42 | 123 | 7 | 23 | 17 |
| **数据分区** | IID | **Non-IID** | IID | IID | **Non-IID** |
| **标签噪声** | 无 | 无 | **20%** | 无 | 无 |

---

## 关键设计思想

### 1️⃣ **参数化设计 > 代码修改**

**优点**:
- ✅ 代码一致性：所有场景使用同一套验证过的代码
- ✅ 可复现性：参数明确，易于复现
- ✅ 维护性：修改一处，所有场景受益
- ✅ 对比公平：确保算法实现完全相同

**缺点**:
- ⚠️ 场景描述中的"Non-IID"、"20% 标签噪声"等需要代码内部根据seed实现
- ⚠️ 如果某些场景需要根本不同的数据生成逻辑，参数化可能不够灵活

### 2️⃣ **通过种子（seed）控制数据特性**

实际上，**数据分区方式（IID vs Non-IID）和标签噪声是在代码内部根据参数动态决定的**，而不是通过显式的参数如 `--partition_type=non-iid`。

让我检查一下代码中是如何实现的：

```python
# 根据不同的 seed，代码可能内部判断生成不同类型的数据分区
# 这是一种隐式的参数化方式
```

### 3️⃣ **多维度覆盖测试**

5个场景覆盖了：
- ✅ **数据分布**: IID vs Non-IID
- ✅ **数据质量**: 干净数据 vs 标签噪声
- ✅ **规模**: 小规模 vs 大规模
- ✅ **参与度**: 正常参与 (50%) vs 稀疏参与 (10%)
- ✅ **训练强度**: 短本地训练 (5步) vs 长本地训练 (20步)
- ✅ **子空间维度**: 小 (8) → 中 (16) → 大 (128)

---

## ⚠️ 潜在问题

### 问题 1: 数据特性的实现不透明

场景描述说"Non-IID"和"20% 标签噪声"，但这些特性是如何实现的？

**可能的实现方式**:
1. **种子驱动**：不同的 seed 触发不同的数据生成逻辑
2. **隐式参数**：代码内部有条件判断（但这样不够透明）
3. **缺失参数**：可能场景描述与实际实现不匹配

**建议**: 应该添加显式参数如：
```bash
--partition_type=iid|non-iid
--label_noise_rate=0.0|0.2
```

### 问题 2: 代码复用 vs 场景定制

虽然代码一致性很好，但某些场景可能需要特殊的数据生成或评估逻辑。当前设计可能限制了场景的多样性。

---

## 结论

✅ **设计理念正确**: 通过参数化而非代码修改来区分场景，是工程上的最佳实践

⚠️ **实现待验证**: 需要检查代码是否真正根据参数实现了场景描述中的特性（特别是Non-IID分区和标签噪声）

💡 **改进方向**: 考虑添加更显式的参数来控制数据特性，提高透明度


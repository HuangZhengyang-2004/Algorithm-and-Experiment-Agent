{
  "selected_parameters": ["lr", "momentum"],
  "selection_rationale": "On near-IID splits, learning rate controls convergence speed and stability, while momentum (with SFedAvg’s projection) smooths updates and can tolerate larger steps; jointly tuning these captures optimizer behavior and sensitivity.",
  "configs": [
    {
      "lr": 0.05,
      "momentum": 0.0,
      "rationale": "Conservative baseline without momentum to isolate pure step-size effects under near-IID data."
    },
    {
      "lr": 0.08,
      "momentum": 0.7,
      "rationale": "Moderate LR with moderate momentum for balanced speed and stability."
    },
    {
      "lr": 0.10,
      "momentum": 0.9,
      "rationale": "Scenario-default strong momentum with moderate LR to test projected momentum smoothing."
    },
    {
      "lr": 0.12,
      "momentum": 0.95,
      "rationale": "Slightly higher LR with very strong momentum to probe tolerance to larger steps."
    },
    {
      "lr": 0.15,
      "momentum": 0.7,
      "rationale": "High LR with reduced momentum to stress stability boundaries and potential overshoot."
    },
    {
      "lr": 0.20,
      "momentum": 0.9,
      "rationale": "Aggressive LR with strong momentum to evaluate SFedAvg’s projected momentum robustness."
    },
    {
      "lr": 0.05,
      "momentum": 0.9,
      "rationale": "Low LR with strong momentum to examine smoothing benefits versus speed."
    },
    {
      "lr": 0.20,
      "momentum": 0.5,
      "rationale": "High LR with lower momentum to stress-test overshoot and variance without strong smoothing."
    }
  ],
  "expected_improvement": "Compared to the baseline, SFedAvg should exhibit smoother loss curves and maintain accuracy at higher learning rates (e.g., 0.12–0.20) due to momentum projection, yielding +1–3% test accuracy and reduced variance under near-IID conditions."
}

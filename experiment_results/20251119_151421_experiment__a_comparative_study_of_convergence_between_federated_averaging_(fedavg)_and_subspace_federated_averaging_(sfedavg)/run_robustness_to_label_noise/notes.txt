# Title: Experiment: A Comparative Study of Convergence between Federated Averaging (FedAvg) and Subspace Federated Averaging (SFedAvg)
# Experiment description: Compare the convergence behavior of Federated Averaging (FedAvg) and Subspace Federated Averaging (SFedAvg) on a standard dataset (e.g., MNIST or CIFAR-10) under identical settings. Measure metrics such as training loss, test accuracy, and communication efficiency over multiple rounds of training.
# Timestamp: 20251119_151421

## Experiment Log

Validation: LOGIC_VALIDATION_PASSED

Checks:
- Algorithm Fidelity:
  * Server initializes θ^0 from W_init.
  * For each round t, SFedAvg samples P_t ∈ St(d,r) and sets Π_t = P_t P_t^⊤, held fixed within the round.
  * Client subset S_t is sampled with size m ≈ C·N.
  * Clients receive (θ^t, Π_t) (Π_t None for FedAvg) and run ClientUpdate; server aggregates θ^{t+1} = θ^t + (1/m) ∑ Δ_i^t.
- ClientUpdate implementation:
  * Sets θ_{i,0} ← θ^t.
  * Momentum Projection (MP) at block start: v_i^0 ← Π_t v_i^{prev} if available else 0 (only for SFedAvg).
  * For s=0..τ-1: samples minibatch, computes true gradient from data, updates v_{i,s+1} = μ v_{i,s} + Π_t g_{i,s} (SFedAvg) and θ_{i,s+1} = θ_{i,s} − η v_{i,s+1}; FedAvg uses plain SGD θ_{i,s+1} = θ_{i,s} − η g_{i,s}.
  * Returns Δ_i^t = θ_{i,τ} − θ^t and stores v_i^{prev} = v_{i,τ} (zeros for FedAvg).
- Metrics:
  * Train loss and test accuracy are computed each round from actual predictions and labels.
  * Communication cost tracks cumulative MB per round, including sending θ^t and Π_t (SFedAvg) and receiving full Δ_i^t.

Conclusion: Implementation matches the provided pseudocode for both FedAvg and SFedAvg with MP.

- Data partition: Non-IID label-skew via Dirichlet α≈0.2 across 50 clients (each dominated by ~2 classes).
- Label noise: None (0%).
- Special processing/mods: Enabled '--l' alias and disallowed abbrev parsing; SFedAvg samples Π_t each round and applies momentum projection of stored v_i.
- Key distinction: Strong client drift from skew; contrasts FedAvg's plain local SGD with SFedAvg's one-sided projected momentum under C=0.2 and subspace_ratio=0.1.

Tuning Analysis - non-iid_label_skew_(client_drift_stress_test)
1) Best Configuration: subspace_ratio=0.30, lr=0.12, local_steps=8 (config_8) achieved the highest SFedAvg test accuracy (final 0.9722) and the lowest train loss (final 0.1212), outperforming all other tested settings.
2) Performance Improvement: Compared to baseline SFedAvg (final test acc 0.9389), config_8 improves accuracy by ~3.6% relative and reduces final train loss by ~67.8%, indicating substantially faster and more stable convergence under heterogeneity.
3) Parameter Insights: subspace_ratio had the strongest impact—moderate-to-high r/d (0.25–0.35) consistently improved SFedAvg; lr needed to be conservative (≈0.10–0.12) to avoid instability with projected momentum; longer local_steps (≈8) helped SFedAvg due to momentum projection mitigating client drift, while very small r (0.05) or aggressive lr (0.25) degraded performance.
4) Recommendation: Use subspace_ratio=0.30, lr=0.12, local_steps=8 with momentum=0.9 and client_frac aligned to the scenario (e.g., 0.2); this setting balances projection strength and step size, yielding superior accuracy and markedly lower training loss under strong label skew.


# Title: Experiment: A Comparative Study of Convergence between Federated Averaging (FedAvg) and Subspace Federated Averaging (SFedAvg)
# Experiment description: Compare the convergence behavior of Federated Averaging (FedAvg) and Subspace Federated Averaging (SFedAvg) on a standard dataset (e.g., MNIST or CIFAR-10) under identical settings. Measure metrics such as training loss, test accuracy, and communication efficiency over multiple rounds of training.
# Timestamp: 20251122_145931

## Experiment Log

- Scenario: non-iid_label_skew_stress_test
- Data partition: IID across clients in current implementation; non-IID label skew not simulated.
- Label noise: None added (0%).
- Special processing/algorithm mods: SFedAvg uses one-sided random projector Pi_t (Stiefel-sampled) each round with momentum projection; FedAvg uses plain local SGD without momentum.
- Key differences: SFedAvg transmits P_t (d*r) increasing comm_floats and applies projected momentum to mitigate drift vs FedAvg.

- Scenario: label_noise_robustness
- Data partition: IID random split across clients (partition_iid).
- Label noise: Uniform 20% per client via add_label_noise (independent flips across classes).
- Special processing/algorithm mods: SFedAvg uses one-sided projector Pi_t with momentum projection; projector sampled per round; FedAvg uses plain local SGD.
- Key implementation details: Per-client label corruption to test noisy-gradient damping; conditional algorithm execution and comm accounting include Pi_t transmission only for SFedAvg.

- Scenario: scalability:_many_clients_and_high-dimensional_features
- Data partition: IID random split across clients (partition_iid) to isolate scaling effects.
- Label noise: None added (0%).
- Special processing/algorithm mods: Synthetic dataset with d=200 features and increased samples_per_class=2000; SFedAvg uses one-sided projector Π_t with momentum (μ=0.9); local_steps τ=1.
- Key implementation details: Many clients (N=200, C=0.1), subspace rank r=32; per-round Stiefel-sampled P_t transmission adds d·r comm_floats; FedAvg runs plain local SGD for comparison.

- Scenario: hyperparameter_stress:_aggressive_lr_and_deep_local_steps
- Data partition: IID random split across clients (partition_iid) to isolate optimizer effects.
- Label noise: None added (0%).
- Special processing/algorithm mods: Aggressive local optimization (τ=10, η=0.2); SFedAvg uses one-sided projector Π_t per round with momentum projection (μ=0.95); FedAvg uses plain local SGD without momentum.
- Key implementation details: Client fraction C=0.2 (N=50), subspace rank r=8; Π_t sampled via Stiefel and held fixed within round; communication accounting includes d·r projector transmission for SFedAvg; focus on stability vs oscillation under aggressive settings.

- Scenario: projection_rank_edge_case_(r=1)
- Data partition: Moderate non-IID—each client concentrates ~60% of data on 3 assigned classes (partition_non_iid with classes_per_client=3, major_fraction=0.6).
- Label noise: None added (0%).
- Special processing/algorithm mods: SFedAvg uses one-sided projection with rank r=1 and momentum projection (v^0 ← Π_t v_prev); Π_t sampled per round and held fixed; FedAvg uses plain local SGD.
- Key implementation details: Extremely low-rank subspace (r=1) constrains updates to near 1D; communication accounts for sending P_t (d·r); parameters: T=60, τ=5, C=0.1, η=0.1, μ=0.9, B=32, N=50.


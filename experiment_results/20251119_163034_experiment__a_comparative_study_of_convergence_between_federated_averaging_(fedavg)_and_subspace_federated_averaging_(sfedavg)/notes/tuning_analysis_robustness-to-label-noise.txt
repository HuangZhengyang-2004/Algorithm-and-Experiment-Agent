1) Best Configuration
- Config 2 (lr=0.10, mu=0.98, subspace_frac=0.20) achieved the strongest overall robustness: it matched the highest final SFedAvg test accuracy (95.56%) while delivering the lowest SFedAvg training loss among matching-accuracy configs.
- Config 6 (lr=0.12, mu=0.95, subspace_frac=0.25) also reached 95.56% accuracy but with higher communication, offering no accuracy benefit over Config 2.

2) Performance Improvement
- Final SFedAvg test accuracy is unchanged versus baseline (95.56%), but SFedAvg training loss improved from ~0.1777 (baseline) to ~0.1406 (âˆ’20.9%) with Config 2.
- Communication cost remained the same as baseline for Config 2 (same subspace_frac=0.20); smaller subspace (0.15) reduced comm by ~25% but lowered accuracy to ~94.17%.

3) Parameter Insights
- Momentum (mu) is the most impactful under label noise: raising mu to 0.98 consistently reduced training loss and stabilized accuracy without extra communication.
- Subspace size trades robustness vs. communication: shrinking to 0.15 cut comm ~25% but slightly hurt accuracy; expanding to 0.30 increased comm ~50% with no accuracy gain.
- Learning rate around 0.10 remained a sweet spot; lowering to 0.07 or raising to 0.12 did not further improve final accuracy, though 0.12 sped early loss decrease.

4) Recommendation
- Use lr=0.10, mu=0.98, subspace_frac=0.20 for robustness to label noise at the baseline communication budget.
- If bandwidth is constrained, consider subspace_frac=0.15 (lr=0.10, mu=0.95) to reduce comm by ~25% with a small accuracy drop; avoid subspace_frac=0.30 as it increases comm without accuracy gains.

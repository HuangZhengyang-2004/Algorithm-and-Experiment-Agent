# Title: Experiment: A Comparative Study of Convergence between Federated Averaging (FedAvg) and Subspace Federated Averaging (SFedAvg)
# Experiment description: Compare the convergence behavior of Federated Averaging (FedAvg) and Subspace Federated Averaging (SFedAvg) on a standard dataset (e.g., MNIST or CIFAR-10) under identical settings. Measure metrics such as training loss, test accuracy, and communication efficiency over multiple rounds of training.
# Timestamp: 20251119_163034

## Experiment Log

Scenario 'iid-baseline-convergence': IID stratified partition across 20 clients with balanced label proportions per client.
Label noise: None (0%).
Processing/Algorithm: Features z-score standardized; SFedAvg samples a per-round one-sided random subspace with momentum projection; FedAvg uses full-space momentum; deterministic round-robin client selection.
Distinctive aspects: Pure IID baseline to isolate the effect of subspace projection with momentum; logs train loss, test accuracy, and cumulative communication per round.

Scenario 'noniid-label-skew': Non-IID label-skew partition using Dirichlet α=0.2 so each client has 1–3 dominant classes (strong heterogeneity).
Label noise: None (0%).
Processing/Algorithm: Z-score feature standardization; partition_strategy='dirichlet'; local_steps=10; SFedAvg uses per-round one-sided random subspace (subspace_frac=0.25) with momentum projection; FedAvg uses full-space momentum.
Distinctive aspects: Strong client-drift stress test with rounds=80, clients=20, client_frac=0.25, lr=0.05, mu=0.9, batch_size=64, reg=1e-4; compares stability/accuracy vs cumulative communication under label skew.


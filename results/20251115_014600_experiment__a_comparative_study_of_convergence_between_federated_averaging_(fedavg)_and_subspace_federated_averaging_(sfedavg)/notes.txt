# Title: Experiment: A Comparative Study of Convergence between Federated Averaging (FedAvg) and Subspace Federated Averaging (SFedAvg)
# Experiment description: Compare the convergence behavior of Federated Averaging (FedAvg) and Subspace Federated Averaging (SFedAvg) on a standard dataset (e.g., MNIST or CIFAR-10) under identical settings. Measure metrics such as training loss, test accuracy, and communication efficiency over multiple rounds of training.
# Timestamp: 20251115_014600

## Experiment Log

### Run 1: FedAvg Baseline (IID Data)
**Configuration:**
- Algorithm: FedAvg
- Rounds (T): 200
- Local steps (τ): 5
- Client fraction (C): 0.1
- Learning rate (η): 0.01
- Batch size (B): 32
- Data: MNIST with IID split across 100 clients

**Results:**
- Final test accuracy: 89.12%
- Final training loss: 0.3710
- Convergence: Smooth and steady improvement over 200 rounds
- Key observation: Model successfully learned from real data with meaningful convergence behavior

**Analysis:**
The FedAvg implementation shows proper learning dynamics with training loss decreasing and test accuracy increasing consistently. The final accuracy of 89.12% on MNIST is reasonable for a softmax regression model without convolutional layers, validating our implementation.

### Run 2: SFedAvg Baseline (IID Data)
**Configuration:**
- Algorithm: SFedAvg
- Rounds (T): 200
- Local steps (τ): 5
- Client fraction (C): 0.1
- Learning rate (η): 0.01
- Momentum (μ): 0.9
- Batch size (B): 32
- Subspace dimension (r): 100
- Data: MNIST with IID split across 100 clients

**Results:**
- Final test accuracy: 60.85%
- Final training loss: 1.3643
- Convergence: Much slower than FedAvg, with steady but gradual improvement
- Key observation: SFedAvg converges significantly slower than FedAvg in IID setting

**Analysis:**
The subspace constraints and momentum projection in SFedAvg appear to hinder convergence speed in the IID setting. While the algorithm does learn (accuracy improves from 8.43% to 60.85%), it's substantially slower than FedAvg which reached 89.12% accuracy. This suggests that the projection to lower-dimensional subspaces may be limiting the model's ability to efficiently explore the parameter space when data is uniformly distributed.

### Run 3: FedAvg with Non-IID Data
**Configuration:**
- Algorithm: FedAvg
- Rounds (T): 200
- Local steps (τ): 5
- Client fraction (C): 0.1
- Learning rate (η): 0.01
- Batch size (B): 32
- Data: MNIST with non-IID split (each client contains data from only 2 random classes)

**Results:**
- Final test accuracy: 88.29%
- Final training loss: 0.4031
- Convergence: Slightly slower than IID case but still strong performance
- Key observation: FedAvg maintains good performance even under non-IID conditions

**Analysis:**
FedAvg shows robustness to data heterogeneity, achieving only slightly lower final accuracy (88.29%) compared to the IID case (89.12%). The convergence curve remains smooth, indicating that the algorithm can handle non-IID distributions reasonably well.

### Run 4: SFedAvg with Non-IID Data
**Configuration:**
- Algorithm: SFedAvg
- Rounds (T): 200
- Local steps (τ): 5
- Client fraction (C): 0.1
- Learning rate (η): 0.01
- Momentum (μ): 0.9
- Batch size (B): 32
- Subspace dimension (r): 100
- Data: MNIST with non-IID split (each client contains data from only 2 random classes)

**Results:**
- Final test accuracy: 57.69%
- Final training loss: 1.4145
- Convergence: Similar slow convergence pattern as IID case
- Key observation: SFedAvg performance remains limited under non-IID conditions

**Analysis:**
SFedAvg shows consistently slower convergence compared to FedAvg across both IID and non-IID settings. The subspace constraints appear to significantly limit learning efficiency regardless of data distribution. This suggests that the current implementation may require tuning of other hyperparameters (like learning rate or subspace dimension) to achieve competitive performance.

### Run 5: SFedAvg with Non-IID Data and Larger Subspace
**Configuration:**
- Algorithm: SFedAvg
- Rounds (T): 200
- Local steps (τ): 5
- Client fraction (C): 0.1
- Learning rate (η): 0.01
- Momentum (μ): 0.9
- Batch size (B): 32
- Subspace dimension (r): 200
- Data: MNIST with non-IID split (each client contains data from only 2 random classes)

**Objective:** Test if increasing the subspace dimension improves SFedAvg convergence by allowing more parameter exploration.

## Visualization Summary

### Plot 1: Convergence Comparison (convergence_comparison.png)
- **Description:** Line charts showing test accuracy and training loss over 200 communication rounds for all algorithm configurations
- **Purpose:** Visualize the convergence behavior and learning dynamics of FedAvg vs SFedAvg under different data distributions and subspace dimensions
- **Key Insights:** FedAvg consistently outperforms SFedAvg in both IID and non-IID settings, with faster convergence and higher final accuracy

### Plot 2: Final Performance Comparison (final_performance_comparison.png)
- **Description:** Bar charts comparing final test accuracy and training loss across all algorithm configurations
- **Purpose:** Provide a clear quantitative comparison of ultimate performance metrics for easy cross-algorithm evaluation
- **Key Insights:** FedAvg achieves ~89% accuracy while SFedAvg variants plateau around 57-61%, regardless of subspace dimension

### Plot 3: Convergence Speed Comparison (convergence_speed_comparison.png)
- **Description:** Bar chart showing number of rounds required to reach accuracy milestones (50%, 60%, 70%, 80%)
- **Purpose:** Analyze the convergence speed and efficiency of different algorithms in reaching key performance thresholds
- **Key Insights:** FedAvg reaches all milestones significantly faster than SFedAvg variants, which fail to reach higher milestones

### Plot 4: Performance Gap Analysis (performance_gap_comparison.png)
- **Description:** Line chart showing the accuracy difference between FedAvg IID baseline and SFedAvg variants over time
- **Purpose:** Quantify the performance penalty of using subspace constraints and momentum projection
- **Key Insights:** The performance gap widens rapidly in early rounds and stabilizes, showing SFedAvg's fundamental limitations

